{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import FastText\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "from keras.layers import Embedding,Dense,LSTM, Dropout, Flatten, Convolution1D, MaxPooling1D\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "model = FastText.load_fasttext_format('wiki.en/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing - removing unwanted characters, tokenization, stop-word removal\n",
    "def clean_data(txts):\n",
    "    x = re.sub(\"[^a-zA-Z]\", \" \",txts) \n",
    "    x = x.lower().split()                             \n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    words = [w for w in x if not w in stops] \n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_norm(txts):\n",
    "    x = re.sub('(OntoBiotope |)','',txts)\n",
    "    x = re.sub('(:|_)',' ',x)\n",
    "    x = re.sub('(Taxonomy)','taxon',x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_norm+Dev_norm appended (same as Train_norm+ner, Dev_norm+ner appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3268, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>entity</th>\n",
       "      <th>norm1</th>\n",
       "      <th>norm2</th>\n",
       "      <th>norm3</th>\n",
       "      <th>norm4</th>\n",
       "      <th>norm5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>selective broths based on hypertonic strontium...</td>\n",
       "      <td>Habitat</td>\n",
       "      <td>OntoBiotope OBT:000360</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selective broths based on the bi-selenite ion</td>\n",
       "      <td>Habitat</td>\n",
       "      <td>OntoBiotope OBT:000360</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salmonellae</td>\n",
       "      <td>Microorganism</td>\n",
       "      <td>NCBI_Taxonomy 590</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>egg products</td>\n",
       "      <td>Habitat</td>\n",
       "      <td>OntoBiotope OBT:001086</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>egg</td>\n",
       "      <td>Habitat</td>\n",
       "      <td>OntoBiotope OBT:001847</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words         entity  \\\n",
       "0  selective broths based on hypertonic strontium...        Habitat   \n",
       "1      selective broths based on the bi-selenite ion        Habitat   \n",
       "2                                        Salmonellae  Microorganism   \n",
       "3                                       egg products        Habitat   \n",
       "4                                                egg        Habitat   \n",
       "\n",
       "                    norm1 norm2 norm3 norm4 norm5  \n",
       "0  OntoBiotope OBT:000360                          \n",
       "1  OntoBiotope OBT:000360                          \n",
       "2       NCBI_Taxonomy 590                          \n",
       "3  OntoBiotope OBT:001086                          \n",
       "4  OntoBiotope OBT:001847                          "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "data['norm2'].fillna(value='', inplace=True)\n",
    "data['norm3'].fillna(value='', inplace=True)\n",
    "data['norm4'].fillna(value='', inplace=True)\n",
    "data['norm5'].fillna(value='', inplace=True)\n",
    "\n",
    "data = data.drop(data[data.entity == 'Paragraph'].index)\n",
    "data = data.drop(data[data.entity == 'Title'].index)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(path):\n",
    "    z=[]\n",
    "    df_dat = pd.DataFrame(columns = ['text','words','entity'])\n",
    "    org_dat = os.listdir(path)\n",
    "    for i in range(len(org_dat)):\n",
    "        org1 = org_dat[i]\n",
    "        if org1.endswith('.a1'):\n",
    "            org_path1 = os.path.join(path,org1)\n",
    "            text1 = pd.read_table(org_path1,header = None)\n",
    "            for j in range(0,text1.shape[0]):\n",
    "                #print(org1,org2)\n",
    "                #print(text1.iloc[j][2],re.sub(r'[0-9; ]','',text1.iloc[j][1]))\n",
    "                z.append(org1)\n",
    "                df_dat = df_dat.append({'text':text1.iloc[j][0] ,'words': text1.iloc[j][2], 'entity': re.sub(r'[0-9; ]','',text1.iloc[j][1]) }, ignore_index = True)\n",
    "                #print(df_dat)\n",
    "        \n",
    "    return df_dat,z  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'BioNLP-OST-2019_BB-norm_test'\n",
    "df_test,z = get_test_data(path)\n",
    "\n",
    "print(df_test.shape)\n",
    "\n",
    "df_test = df_test.drop(df_test[df_test.entity == 'Paragraph'].index)\n",
    "df_test = df_test.drop(df_test[df_test.entity == 'Title'].index)\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977, 2)\n",
      "(1818, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Microorganism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial pathogenicity</td>\n",
       "      <td>Phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infected germfree piglets</td>\n",
       "      <td>Habitat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Microorganism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intestinal</td>\n",
       "      <td>Habitat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       words         entity\n",
       "2           Escherichia coli  Microorganism\n",
       "3    bacterial pathogenicity      Phenotype\n",
       "4  infected germfree piglets        Habitat\n",
       "5           Escherichia coli  Microorganism\n",
       "6                 intestinal        Habitat"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv('test.csv')\n",
    "# print(test.shape)\n",
    "\n",
    "# test = test.drop(test[test.entity == 'Paragraph'].index)\n",
    "# test = test.drop(test[test.entity == 'Title'].index)\n",
    "# print(test.shape)\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['words'] = data['words'].apply(lambda x: clean_data(x))\n",
    "test = df_test\n",
    "test['words'] = test['words'].apply(lambda x: clean_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = data['words'].tolist()\n",
    "data_entity = data['entity'].tolist()\n",
    "\n",
    "test_words = test['words'].tolist()\n",
    "test_entity = test['entity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3268, 600)\n",
      "(1818, 600)\n"
     ]
    }
   ],
   "source": [
    "X1_train= np.zeros((len(data_words),300)) \n",
    "X2_train= np.zeros((len(data_entity),300)) \n",
    "\n",
    "for i in range(len(data_words)):\n",
    "    words = word_tokenize(data_words[i])\n",
    "    emb = [model.wv[w] for w in words] \n",
    "    X1_train[i] = np.mean(emb, axis=0) \n",
    "    \n",
    "for w in data_entity:\n",
    "    X2_train[i] = model.wv[w]\n",
    "    \n",
    "X_train= np.concatenate((X1_train,X2_train),axis=1)\n",
    "print(X_train.shape)\n",
    "\n",
    "X1_test= np.zeros((len(test_words),300)) \n",
    "X2_test= np.zeros((len(test_entity),300)) \n",
    "\n",
    "for i in range(len(test_words)):\n",
    "    words = word_tokenize(test_words[i])\n",
    "    emb = [model.wv[w] for w in words] \n",
    "    X1_test[i] = np.mean(emb, axis=0) \n",
    "    \n",
    "for w in test_entity:\n",
    "    X2_test[i] = model.wv[w]  \n",
    "    \n",
    "    \n",
    "X_test = np.concatenate((X1_test,X2_test),axis=1)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.DataFrame(X_train)\n",
    "df_test= pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(value=0,inplace=True)\n",
    "df_test.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1818, 600)\n",
      "(3268, 600)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(df_test)\n",
    "X_train = np.array(df_train)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm1 = data['norm1'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3268,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(data_norm1)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = RandomForestClassifier(n_estimators=30,criterion='entropy',class_weight='balanced')\n",
    "model_class.fit(X_train,Y)\n",
    "pre = model_class.predict(X_test)\n",
    "# print(accuracy_score(y_test,pre))\n",
    "# print(confusion_matrix(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = le.inverse_transform(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'words':test['words'],'entity':test['entity'],'norm':norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1\\tNCBI_Taxonomy Annotation:T3 Referent:562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1\\tOntoBiotope Annotation:T4 Referent:OBT:000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2\\tOntoBiotope Annotation:T5 Referent:OBT:003206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N4\\tNCBI_Taxonomy Annotation:T6 Referent:562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N4\\tOntoBiotope Annotation:T7 Referent:OBT:002810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0       N1\\tNCBI_Taxonomy Annotation:T3 Referent:562\n",
       "1  N1\\tOntoBiotope Annotation:T4 Referent:OBT:000375\n",
       "2  N2\\tOntoBiotope Annotation:T5 Referent:OBT:003206\n",
       "3       N4\\tNCBI_Taxonomy Annotation:T6 Referent:562\n",
       "4  N4\\tOntoBiotope Annotation:T7 Referent:OBT:002810"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_data(path):\n",
    "#     z=[]\n",
    "#     df_dat = pd.DataFrame(columns = ['text','words','entity'])\n",
    "#     org_dat = os.listdir(path)\n",
    "#     for i in range(len(org_dat)):\n",
    "#         org1 = org_dat[i]\n",
    "#         if org1.endswith('.a1'):\n",
    "#             org_path1 = os.path.join(path,org1)\n",
    "#             text1 = pd.read_table(org_path1,header = None)\n",
    "#             for j in range(0,text1.shape[0]):\n",
    "#                 #print(org1,org2)\n",
    "#                 #print(text1.iloc[j][2],re.sub(r'[0-9; ]','',text1.iloc[j][1]))\n",
    "#                 z.append(org1)\n",
    "#                 df_dat = df_dat.append({'text':text1.iloc[j][0] ,'words': text1.iloc[j][2], 'entity': re.sub(r'[0-9; ]','',text1.iloc[j][1]) }, ignore_index = True)\n",
    "#                 #print(df_dat)\n",
    "        \n",
    "#     return df_dat,z  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977, 3)\n",
      "(1818, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Microorganism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>bacterial pathogenicity</td>\n",
       "      <td>Phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>infected germfree piglets</td>\n",
       "      <td>Habitat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Microorganism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>intestinal</td>\n",
       "      <td>Habitat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text                      words         entity\n",
       "2   T3           Escherichia coli  Microorganism\n",
       "3   T4    bacterial pathogenicity      Phenotype\n",
       "4   T5  infected germfree piglets        Habitat\n",
       "5   T6           Escherichia coli  Microorganism\n",
       "6   T7                 intestinal        Habitat"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = 'BioNLP-OST-2019_BB-norm_test'\n",
    "# df_test,z = get_test_data(path)\n",
    "\n",
    "# print(df_test.shape)\n",
    "\n",
    "# df_test = df_test.drop(df_test[df_test.entity == 'Paragraph'].index)\n",
    "# df_test = df_test.drop(df_test[df_test.entity == 'Title'].index)\n",
    "# print(df_test.shape)\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_test['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation=[]\n",
    "for i in range(0,norm.shape[0]):\n",
    "    if 'NCBI' in norm[i]:\n",
    "        annotation.append(f'N{i+1}\\tNCBI_Taxonomy Annotation:{text[i]} Referent:{os.path.splitext(norm[i])[0][14:]}')\n",
    "        \n",
    "    elif 'OntoBiotope' in norm[i]:\n",
    "        annotation.append(f'N{i}\\tOntoBiotope Annotation:{text[i]} Referent:{os.path.splitext(norm[i])[0][12:]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('BioNLP-OST-2019_BB-norm_train/BB-norm-448557.a1',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2941, 600), (327, 600), (2941,), (327,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_train,Y,test_size=0.10,random_state=42)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125382262996942\n",
      "[[4 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "model_class = RandomForestClassifier(n_estimators=30,criterion='entropy',class_weight='balanced')\n",
    "model_class.fit(x_train,y_train)\n",
    "pre = model_class.predict(x_test)\n",
    "print(accuracy_score(y_test,pre))\n",
    "print(confusion_matrix(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = le.inverse_transform(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'words':test['words'],'entity':test['entity'],'norm':norm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
